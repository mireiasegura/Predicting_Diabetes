{"cells":[{"cell_type":"markdown","source":["<h1><center>DIABETES EN LAS MUJERES PIMA</center></h1>\n\n **PROYECTO FIN DE MÁSTER**\n\nMireia Segura Sánchez     \n21 de junio de 2018        \n\n_Máster Telefónica en Big Data & Business Analytics_    \nTutor: Javier Rodríguez Martín   \n   \n      \n         \n         \n   \n  \n  \n## ÍNDICE \n+ [1. INTRODUCCIÓN CON EL OBJETIVO DEL ANÁLISIS](https://community.cloud.databricks.com/?o=3185991083556977#notebook/3164243914005431/command/3945915022333819)  \n+ [2. CARGA DE DATOS Y ANÁLISIS DESCRIPTIVO](https://community.cloud.databricks.com/?o=3185991083556977#notebook/3164243914005431/command/3945915022333817)    \n  - [2.1 PREPROCESADO Y LIMPIEZA DE DATOS](https://community.cloud.databricks.com/?o=3185991083556977#notebook/3164243914005431/command/3945915022333817)  \n  - [2.2 ANÁLISIS DESCRIPTIVO](https://community.cloud.databricks.com/?o=3185991083556977#notebook/3164243914005431/command/3945915022333822)  \n+ [3. ANÁLISIS EXPLORATORIO APOYADO EN MÉTODO NO SUPERVISADO](https://community.cloud.databricks.com/?o=3185991083556977#notebook/3164243914005431/command/3945915022333824)  \n  - [3.1 DISTRIBUCIÓN DE LA CLASIFICACIÓN EN CADA VARIABLE](https://community.cloud.databricks.com/?o=3185991083556977#notebook/3164243914005431/command/3520562411919711)  \n  - [3.2 VISUALIZACIÓN INTERACTIVA CON TABLEAU](https://community.cloud.databricks.com/?o=3185991083556977#notebook/3164243914005431/command/2068191741099411)  \n  - [3.3 CORRELACIONES](https://community.cloud.databricks.com/?o=3185991083556977#notebook/3164243914005431/command/3520562411919712)  \n  - [3.4 SPLIT DE DATOS ENTRENAMIENTO Y TEST](https://community.cloud.databricks.com/?o=3185991083556977#notebook/3164243914005431/command/3520562411919713)  \n  - [3.5 APRENDIZAJE AUTOMÁTICO NO SUPERVISADO. CLUSTERING CON K-MEANS](https://community.cloud.databricks.com/?o=3185991083556977#notebook/3164243914005431/command/3520562411919714)\n+ [4. APRENDIZAJE AUTOMÁTICO SUPERVISADO (CLASIFICACIÓN)](https://community.cloud.databricks.com/?o=3185991083556977#notebook/3164243914005431/command/4414866969626766)  \n  - [4.1 REGRESIÓN LOGÍSTICA CON VALIDACIÓN CRUZADA](https://community.cloud.databricks.com/?o=3185991083556977#notebook/3164243914005431/command/3503273585082725)\n  - [4.2 GRADIENT-BOOSTED TREE CON VALIDACIÓN CRUZADA](https://community.cloud.databricks.com/?o=3185991083556977#notebook/3164243914005431/command/3503273585082726)\n  - [4.3 ÁRBOLES DE DECISIÓN CON VALIDACIÓN CRUZADA](https://community.cloud.databricks.com/?o=3185991083556977#notebook/3164243914005431/command/3503273585082727)  \n  - [4.4 LINEAR SUPPORT VECTOR MACHINE (SVM) CON VALIDACIÓN CRUZADA](https://community.cloud.databricks.com/?o=3185991083556977#notebook/3164243914005431/command/3503273585082728)\n+ [5. EVALUACIÓN Y COMPARACIÓN DE MODELOS](https://community.cloud.databricks.com/?o=3185991083556977#notebook/3164243914005431/command/4414866969626767)  \n+ [6. CONCLUSIONES](https://community.cloud.databricks.com/?o=3185991083556977#notebook/3164243914005431/command/4414866969626768)  \n+ [7. REFERENCIAS](https://community.cloud.databricks.com/?o=3185991083556977#notebook/3164243914005431/command/4180744964594993)"],"metadata":{}},{"cell_type":"markdown","source":["##1. INTRODUCCIÓN CON EL OBJETIVO DEL ANÁLISIS \n\nEste proyecto de fin de máster se centra en el estudio de la diabetes en mujeres dado el dataset [Pima Indian Diabetes](https://www.kaggle.com/uciml/pima-indians-diabetes-database/data) (UCI Machine Learning). El objetivo es predecir la probabilidad de que las pacientes tengan diabetes, mediante la construcción de modelos Machine Learning en un entorno PySpark (Apache Spark 2.3.0 en Databricks). \n\nSi bien hay muchas condiciones y problemas asociados con la diabetes, como la obesidad y los problemas cardíacos, la enfermedad en sí misma se define sólo por los niveles de glucosa en plasma, lo que se traduce como tener un alto nivel de azúcar en la sangre. \n\nSe estima que la prevalencia mundial de la diabetes en adultos está en torno al 9%, y que fue la causante de 1,6 millones de muertes en 2015 según la [OMS](http://www.who.int/es/news-room/fact-sheets/detail/diabetes). Sin embargo, muchas personas con diabetes no presentan síntomas clínicos a simple vista. Esto implica que cuando se diagnostica la enfermedad la mayoría presenta alguna complicación. De hecho, padecerla supone un elevado riesgo de infarto de miocardio, accidente cerebrovascular, ceguera, insuficiencia renal, amputación de miembros inferiores y como ya hemos comentado, la muerte _[(El Economista)](https://www.eleconomista.com.mx/arteseideas/La-diabetes-con-cifras-excesivas-y-en-crecimiento-20171113-0097.html). _\n\nAlrededor de 205 millones de mujeres en el mundo sufren esta enfermedad. Durante el embarazo, la hiperglucemia aumenta sustancialmente el riesgo para la salud tanto de la madre como del niño, así como el riesgo de diabetes para el niño en el futuro. Casi la mitad de las mujeres que mueren en países de bajos ingresos debido a niveles altos de glucosa en sangre mueren prematuramente, antes de los 70 años [(_OMS_)](http://apps.who.int/iris/bitstream/handle/10665/204871/9789241565257_eng.pdf;jsessionid=A6F8442DD9924FD15DF258533FCFF198?sequence=1).\n\n\nExisten tres tipos de diabetes:    \n-Tipo I: es dependiente de la insulina y a menudo se llama diabetes de inicio juvenil.    \n-Tipo II: la más común. No depende de la insulina, y a menudo se llama \"aparición en el adulto\" ya que es más frecuente en personas mayores de 40 años.   \n-Diabetes gestacional: aparece durante el embarazo.    \n\n\nLa diabetes tipo 2 se asocia con la obesidad y el envejecimiento. Es una enfermedad dependiente del estilo de vida y tiene un fuerte componente genético (la concordancia en gemelos es del 80-90%). El problema no parece ser tanto en la producción de insulina, sino que cuando la insulina alcanza las células diana, ésta no funciona correctamente. La mayoría de los pacientes con diabetes tipo II inicialmente tienen niveles altos de insulina junto con niveles altos de azúcar en la sangre. Sin embargo, dado que el azúcar envía señales al páncreas para que libere insulina, los diabéticos Tipo II eventualmente se vuelven resistentes a esa señal y el páncreas endocrino pronto deja de producir suficiente insulina. Estas personas terminan manejando la enfermedad con insulina y necesitan dosis mucho más altas porque son resistentes a ella _(Baier.L y Hansen.R ,2010)_.\n\n\nEn este contexto, los Pima (también conocidos como \"gente del río\"), nativos norteamericanos que tradicionalmente vivían a lo largo de los ríos Gila y Salt en Arizona(EEUU), son la población con mayor prevalencia de diabetes tipo 2 en el mundo _(Schulz et al., 2006)_. \n\nDurante años, han sido objeto de un estudio intensivo de la diabetes ya que forman un grupo culturalmente cohesionado, que permite extraer conclusiones sobre un entorno determinado. Aún así, hasta ahora no se ha utilizado en ninguno de ellos la tecnología de PySpark.    \nSe cree que el aumento general de la prevalencia de diabetes entre los nativos americanos se ha formulado como resultado de la interacción de la predisposición genética (el fenotipo ahorrativo o el genotipo ahorrativo), y un cambio repentino en la dieta durante el último siglo desde los cultivos agrícolas tradicionales a los alimentos procesados, junto con una disminución de la actividad física _(Booth et al., 2017)_. \n\nDados estos motivos, realizar un análisis de datos basado en diferentes características de las mujeres Pima resulta muy interesante para poder profundizar en el estudio de los factores que influencian la aparición de diabetes."],"metadata":{}},{"cell_type":"markdown","source":["## 2. CARGA DE DATOS Y ANÁLISIS DESCRIPTIVO \n-------------------------------------------\n###  2.1 PREPROCESADO Y LIMPIEZA DE DATOS \n\n#### Contexto\nTodos los pacientes de este dataset son mujeres de ascendencia Pima, con una edad igual o superior a los 21 años.\n\n#### Descripción de variables\n\n- Pregnancies: Número de embarazos.\n- Glucose: Concentración de glucosa plasmática a 2 horas en una prueba de tolerancia oral a la glucosa (mg/dl).\n- BloodPressure: Presión arterial diastólica (mm Hg).\n- SkinThickness: Grosor del pliegue de la piel del tríceps (mm).\n- Insulin: Insulina en suero de 2 horas (mu U / ml).\n- BMI: Índice de masa corporal (peso en kg / (altura en m) ^ 2).\n- DiabetesPedigreeFunction: Función ascendencia de diabetes (factor hereditario).\n- Age: Edad (años).\n- Outcome: Variable de clase (0= no tiene diabetes, 1= tiene diabetes).\n\n#### Carga de datos   \nCreamos un DataFrame asegurando que la variable objetivo (diabetes, reemplazado por outcome) es DoubleType"],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql.types import *\n\ndiabetesSchema=StructType([\n  StructField(\"Pregnancies\", IntegerType(), True),\n  StructField(\"Glucose\", IntegerType(), True),\n  StructField(\"BloodPressure\", IntegerType(), True),\n  StructField(\"SkinThickness\", IntegerType(), True),\n  StructField(\"Insulin\", IntegerType(), True),\n  StructField(\"BMI\", DoubleType(), True),\n  StructField(\"DiabetesPedigreeFunction\", DoubleType(), True),\n  StructField(\"Age\", IntegerType(), True),\n  StructField(\"Diabetes\", DoubleType(), True)])\ndiabetesDF= sqlContext.read.format('com.databricks.spark.csv'). options(header='true', inferSchema='true').load('dbfs:/FileStore/tables/diabetes.csv', schema=diabetesSchema)\ndiabetesDF.show(10)\n\ndiabetesDF.printSchema()\n"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":["#### Limpieza de datos\n\nAlgunas variables presentan valores = 0 que no tienen sentido (por ejemplo, presión sanguínea igual a 0). Esto significa que debemos tratar como nulos todos aquellos ceros presentes en las columnas diferentes de Pregnancies y Diabetes.  \nPor otro lado, para no reducir el tamaño de nuestras observaciones, los reemplazaremos por la media de cada columna."],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql import functions as F\n\n# Pimero reemplazamos los 0 por NA en aquellas columnas donde no tenga sentido\nfor col_name in ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'Age', 'DiabetesPedigreeFunction']:\n  diabetesDF = diabetesDF.withColumn(col_name,F.when(diabetesDF[col_name]==0,F.lit(None)).otherwise(diabetesDF[col_name]))\n\ndiabetesDF.show(10)\n\n# Mostramos el total de reemplazos por columna\ndiabetesDF.select([F.count(F.when(F.isnan(c) | F.col(c).isNull(), c)).alias(c) for c in diabetesDF.columns]).show()\n\n# Creamos una funcion que sustituye los valores NA por la media de cada columna\ndef fill_with_mean(diabetesDF): \n  for col_name in ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI','Age', 'DiabetesPedigreeFunction']:\n    stats = diabetesDF.agg(*(F.avg(col_name).alias(col_name) for col_name in diabetesDF.columns))\n    return diabetesDF.na.fill(stats.first().asDict())\n\ndiabetesDF=fill_with_mean(diabetesDF)\n\ndiabetesDF.show(10)"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":["### 2.2 ANÁLISIS DESCRIPTIVO  \nVemos las dimensiones del DataFrame. Tenemos un total de 768 observaciones y 9 variables.  \nEn cuanto a las estadísticas descriptivas, las pacientes de la muestra tienen una edad media de 33 años y 3.8 embarazos. Además, el índice de masa corporal ronda en torno a 32.46, por lo que estas pacientes cuentan con una obesidad moderada. Los mínimos y máximos valores de glucosa son 44 y 199 mg/dl respectivamente, por lo que tenemos casos de ambos extremos (hipoglucemia y diabéticas).  \nPor último, contamos el número de pacientes con diabetes (268) y sin(500). Debemos tener en cuenta esta desigualdad antes de continuar con el análisis."],"metadata":{}},{"cell_type":"code","source":["# Dimensiones del DataFrame \nprint((diabetesDF.count(), len(diabetesDF.columns)))\n\n# Estadisticas descriptivas\ndiabetesDF.describe().show()\n\n# Pacientes con diabetes y sin\ndiabetesDF.groupBy('Diabetes').count().show()"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["## 3. ANÁLISIS EXPLORATORIO APOYADO EN MÉTODO NO SUPERVISADO\n\nEl objetivo de este análisis exploratorio es extraer unas primeras conclusiones sobre nuestras variables, que serán la base para la construcción de los posteriores métodos de aprendizaje automático supervisados.  \nPara esto, primero observaremos la distribución de cada una junto con la relación que tienen con dicha clasificación.  \nDespués visualizaremos mediante un dashboard interactivo en Tableau, la relación entre algunas variables predictoras para estudiar su comportamiento y tendencias.  \nSeguidamente identificaremos la correlación entre variables con tal de saber cuáles debemos incluir en el split de datos de entrenamiento y test.  \n\nFinalmente, aplicaremos como método no supervisado el clustering con k-means, con el fin de ver la distribución de los valores que toman las variables en cada una de los agrupaciones."],"metadata":{}},{"cell_type":"markdown","source":["### 3.1 DISTRIBUCIÓN DE LA CLASIFICACIÓN EN CADA VARIABLE\nRepresentamos la distribución de los valores que toma cada variable en la clasificación binaria mediante histogramas. Para esto convertimos el DF a Pandas y diferenciamos en verde aquellos que no tienen diabetes y en rojo los que tienen.  \n\nEs importante examinar la distribución de variables antes de hacer otro tipo de gráficos, ya que puede influir notablemente en los resultados del análisis exploratorio.  \nPor ejemplo en el campo edad, vemos que la mayoría de pacientes son jóvenes de unos 20 años; mientras que en DiabetesPedigreeFunction la mayoría de valores incluidos en la muestra son bajos, dando a entender que en general hay un bajo riesgo por factor hereditario. Por lo tanto, son distribuciones con un claro sesgo positivo y que no diferencian los valores de nuestra clasificación.   \nPor lo que hace a las otras variables, sigue pasando lo mismo con la clasificación diabetes/sin diabetes, y no apreciamos ningún sesgo negativo ni una distribución uniforme.   \n\nEn conclusión, según vemos en estas distribuciones no hay ninguna variable que separe bien los pacientes que tienen diabetes de los que no, cosa que sugiere que los modelos tipo árbol no vayan a ser muy efectivos."],"metadata":{}},{"cell_type":"code","source":["import pandas as pd\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\npdDF=diabetesDF.toPandas()\ndf_1 = pdDF[pdDF.Diabetes == 1.0]\ndf_0 = pdDF[pdDF.Diabetes == 0.0]\ncolumns = pdDF.columns[:-1]\n\nplt.subplots(figsize=(16,10))\nnumber_features = len(columns)\nfor i,j,  in zip(columns, range(number_features) ):\n    plt.subplot(3,3,j+1)\n    plt.subplots_adjust(wspace=0.5,hspace=0.5)\n    df_0[i].hist(bins=20, color='g', edgecolor='black', label='Sin diabetes')\n    df_1[i].hist(bins=20, color='r', edgecolor='black', label= 'Diabetes')\n    plt.title(i)\n    plt.legend()\ndisplay()"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":["### 3.2 VISUALIZACIÓN INTERACTIVA CON TABLEAU\n\nEnlace en Tableau: https://public.tableau.com/profile/mireia8699#!/vizhome/DIABETESENMUJERESPIMA/PIMAINDIANDIABETES   \n\nIntentaremos descrifrar a simple vista algunas relaciones y tendencias mediante estos diagramas.  \n\nEn el diagrama de líneas de la izquierda vemos que en general aquellas que tienen diabetes presentan un factor hereditario más alto, cosa que concuerda con lo ya comentado en la introducción. Se produce una excepción en la edad de 44 y 72 años, tienen un gran riesgo de heredar la enfermedad pero de momento no se les ha diagnosticado; aún así, al haber solamente una paciente en la última edad podemos decir que las probabilidades de que ocurran estas excepciones son mínimas. En nuestro dataset, a simple vista no se distingue un aumento de diabetes según avanza la edad, pero cabe recordar que según lo comentado en los histogramas nuestras pacientes son mayoritariamente jóvenes.\n\nEn el diagrama de burbujas agrupadas de la derecha apreciamos que la proporción de diabéticas no parece aumentar según su número de embarazos, ya que las burbujas de color más oscuro son más bien pequeñas. El mayor recuento de diabéticas se encuentra en los 25 años, seguido de 29, 31 y 41.\n\nPara apreciar la relación entre ambos gráficos, si clicamos ahora en los dos valores más altos de mujeres con diabetes del diagrama de líneas (pacientes de 33 y 56 años, color granate), vemos que en el diagrama de burbujas la primera edad es también de las más oscuras (mayor cantidad de diabéticas), pero no de las más grandes (pocos embarazos). Sin embargo, ocurre lo contrario en el caso de 56 años: muestra más embarazos pero un número inferior de diabéticas. Lo mismo ocurre si clicamos ahora en el valor más bajo (pacientes de 55, color granate). Por tanto, los gráficos tienen sentido ya que cuanto más mayor sea una mujer más hijos habrá podido tener a lo largo de los años, pero no podemos establecer una tendencia en cuanto a la diabetes y el factor hereditario. \n\nSi ahora clicamos en las burbujas más grandes del diagrama de burbujas (48, 44 y 51 años), vemos que en el primer y último caso las diabéticas presentan unos factores hereditarios bastante altos, mientras que en el segundo ocurre al revés. En conclusión, no podemos asegurar la existencia de una relación positiva o negativa entre el número de embarazos y el factor hereditario de diabetes todavía."],"metadata":{}},{"cell_type":"markdown","source":["### 3.3 CORRELACIONES  \n\nA continuación estudiaremos las correlaciones, un punto clave para entender con más precisión la relación entre variables.  \n\nEn el primer comando revisamos si existen variables altamente correladas para la seleccion de variables predictoras de los modelos. Vemos que no hay ninguna que presente una alta correlación, así que incluiremos todas en el análisis.    \n\nRepresentamos igualmente la matriz de correlación para contrastar los resultados con los diagramas anteriores.   \nDiabetes, al igual que el resto de variables, está positivamente correlacionada con todas las demás. Además podemos destacar una relación bastante relevante entre diabetes y glucosa, el número de embarazos y la edad, índice de masa corporal y grosor de la piel, así como entre insulina y glucosa.  \nSin embargo, el factor hereditario está negativamente correlacionado con la presión arterial y el número de embarazos.   \nPor lo tanto, las conclusiones que hemos sacado del anterior gráfico interactivo eran poco precisas, tal y como ya se esperaba debido al sesgo que presentan las variables."],"metadata":{}},{"cell_type":"code","source":["for i in diabetesDF.columns:\n  for j in diabetesDF.columns:\n    if not( isinstance(diabetesDF.select(i).take(1)[0][0], unicode)) :\n        if(diabetesDF.stat.corr(i,j)>=0.7): \n          print(i, j, diabetesDF.stat.corr(i,j))"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["matriz, cmap=plt.subplots()\ncorr = pdDF[pdDF.columns].corr()\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\nsns.heatmap(corr, cmap=cmap, annot = True)\n\ndisplay(matriz)"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":["### 3.4 SPLIT DE DATOS ENTRENAMIENTO Y TEST"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.feature import VectorAssembler\n\n# Hacemos directamente un vector assembler con las variables predictoras\nvecAssembler= VectorAssembler(inputCols=[\"Pregnancies\",\"Glucose\",\"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\", \"Age\"], outputCol= \"features\")\nvaDf=vecAssembler.transform(diabetesDF)\n\nvaDf.cache()\nvaDf.show(3)\n\n# Creamos conjunto entrenamiento y test\n(trainingData, testData) = vaDf.randomSplit([0.7, 0.3], seed = 124)\nprint \"Observaciones en set entrenamiento: {0}\".format(trainingData.count())\nprint \"Observaciones en set test: {0}\".format(testData.count())"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":["### 3.5 APRENDIZAJE AUTOMÁTICO NO SUPERVISADO. CLUSTERING CON K-MEANS."],"metadata":{}},{"cell_type":"code","source":["# Para encontrar el numero optimo de clusters(k) usamos el metodo elbow mediante la funcion de cost \nfrom pyspark.ml.clustering import KMeans\nimport numpy as np\n\ncost = np.zeros(20)\nfor k in range(2,20):\n    kmeans = KMeans().setK(k).setSeed(1).setFeaturesCol(\"features\")\n    model = kmeans.fit(vaDf.sample(False,0.1, seed=42))\n    cost[k] = model.computeCost(vaDf) \n    \nelbow, ax = plt.subplots(1,1, figsize =(8,6))\nax.plot(range(2,20),cost[2:20])\nax.set_xlabel('k')\nax.set_ylabel('cost')\n\ndisplay(elbow)\n# Parece que a partir de k=4 la variacion entre los clusters(suma de cuadrados) es muy pequeña, asi que utilizaremos ese"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["# Aplicamos el algoritmo k-means con un numero de centroides de 4\nk=4\nkmeans = KMeans().setK(k).setSeed(1234).setFeaturesCol(\"features\")\nk_model = kmeans.fit(vaDf)\n\n# Mostramos los valores para los centroides\ncenters=k_model.clusterCenters()\nfor i in range(k):\n  print \"Centroide del cluster {0}: {1}\".format(i, centers[i])\n\n\n# Vemos el resultado del clustering, asignando las filas individuales a su centroide mas cercano\npredictions_kmeans= k_model.transform(vaDf)\npredictions_kmeans.show(5)\n\n# Vemos el numero de observaciones para cada cluster\ndiabetesDFGroup=predictions_kmeans.groupBy(predictions_kmeans.prediction)\ndiabetesDFGroup.agg({\"*\":\"count\"}).show()\n"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":["#### EVALUACIÓN CLUSTERING  \nEvaluamos el clustering calculando el Silhouette score, el cual indica la capacidad del clustering para separar los elementos en k grupos.  \nEl resultado es un valor algo alto(0.67), por lo que es un clustering bastante fiable dentro de lo que cabe."],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.evaluation import ClusteringEvaluator\n\nevaluator_kmeans = ClusteringEvaluator()\nsilhouette = evaluator_kmeans.evaluate(predictions_kmeans)\nprint(\"Silhouette with squared euclidean distance = \" + str(silhouette))"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":["#### VISUALIZACIÓN K-MEANS. DISTRIBUCIÓN VALORES EN CADA CLÚSTER.   \nRealizamos nuevos histogramas, con el fin de tener una perspectiva sobre la distribución de los valores que toman las variables predictoras en cada uno de los clústers. Para esto transformamos el resultado del clustering a un DataFrame de Pandas, seguidamente seleccionamos los clusters y hacemos los histogramas para cada variable.\n\nPodemos observar que el clúster 1 (en rojo) es donde hay una mayor concentración de pacientes y con diferencia, ya que presenta frecuencias muy altas en todas las variables. Por ejemplo en Pregnancies el recuento más alto corresponde a algo más de 70 pacientes con 1 embarazo, mientras que en Age vemos alrededor de 90 pacientes de 20 años."],"metadata":{}},{"cell_type":"code","source":["pdPrediction=k_model.transform(vaDf).toPandas()\n\ncluster_0=pdPrediction[pdPrediction.prediction == 0]\ncluster_1=pdPrediction[pdPrediction.prediction == 1]\ncluster_2=pdPrediction[pdPrediction.prediction == 2]\ncluster_3=pdPrediction[pdPrediction.prediction == 3]\n\ncolumns = pdDF.columns[:-1]\n\nplt.subplots(figsize=(16,10))\nnumber_features = len(columns)\nfor i,j,  in zip(columns, range(number_features) ):\n    plt.subplot(3,3,j+1)\n    plt.subplots_adjust(wspace=0.5,hspace=0.5)\n    cluster_0[i].hist(bins=20, color='g', edgecolor='black', label='Cluster 0')\n    cluster_1[i].hist(bins=20, color='r', edgecolor='black', label='Cluster 1')\n    cluster_2[i].hist(bins=20, color='b', edgecolor='black', label='Cluster 2')\n    cluster_3[i].hist(bins=20, color='y', edgecolor='black', label='Cluster 3')\n    plt.title(i)\n    plt.legend()\ndisplay()"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":["## 4. APRENDIZAJE AUTOMÁTICO SUPERVISADO (CLASIFICACIÓN)\n\nEn este apartado estudiaremos 4 modelos de aprendizaje automático por clasificación diferentes: Regresión Logística, Gradient-Boosted Tree, Árboles de decisión y SVM.   \n\nUtilizaremos en cada uno la técnica de validación cruzada, la cual garantiza que los resultados son independientes de la partición entre datos de entrenamiento y test, a la vez que nos permite controlar síntomas de sobreajuste. Estableceremos un número de particiones igual a 5, con tal de que el conjunto test sea diferente en cada una de las ejecuciones. Tras varias pruebas, el grid de parámetros presente en el código de cada modelo es el más óptimo."],"metadata":{}},{"cell_type":"markdown","source":["### 4.1 REGRESIÓN LOGÍSTICA CON VALIDACION CRUZADA  \nEs uno de los métodos de clasificación binaria más comunes, cuyo objetivo es modelar la probabilidad de que una observación pertenezca a una determinada clase. Para estimar los valores de los parámetros utiliza la aproximación de la máxima probabilidad."],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n\n\n# Creamos modelo de Regresion Logistica ajustado con k-fold y grid de parametros\nlr = LogisticRegression(labelCol=\"Diabetes\", featuresCol=\"features\", maxIter=10)\nlrevaluator = BinaryClassificationEvaluator(labelCol=\"Diabetes\")\nparamGrid = (ParamGridBuilder()\n             .addGrid(lr.regParam, [0.01, 0.5, 1.0, 2.0])\n             .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\n             .addGrid(lr.maxIter, [1, 5, 10])\n             .build())\ncv_lr = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid, evaluator=lrevaluator, numFolds=5)\ncvModel_lr = cv_lr.fit(trainingData)\n\nprint type(cvModel_lr)\nprint type(cvModel_lr.bestModel)\n\n# Mostramos los coeficientes y el intercept de la regresion logistica\nprint \"Model Intercept: {0}\".format(cvModel_lr.bestModel.intercept) \nprint \"Model Coefficients: {0}\".format(cvModel_lr.bestModel.coefficients) \n\n# Predecimos sobre conjunto test\npredictions_test_lr = cvModel_lr.transform(testData)\npredictions_test_lr.select(\"prediction\", \"Diabetes\", \"features\").show(5)"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":["### 4.2 GRADIENT-BOOSTED TREE CON VALIDACIÓN CRUZADA  \nEl boosting es una técnica de conjunto en la que los predictores no se hacen de forma independiente, sino de forma secuencial. La lógica detrás del concepto \"Gradient-Boosted\" consiste básicamente en fortalecer un modelo con predicciones débiles para mejorarlo."],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.classification import GBTClassifier\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\n\n# Creamos modelo GBT ajustado con k-fold y grid de parametros\ngbt = GBTClassifier(labelCol=\"Diabetes\", featuresCol=\"features\", maxIter=10)\nevaluator_gbt = MulticlassClassificationEvaluator(labelCol=\"Diabetes\")\nparamGrid = (ParamGridBuilder()\\\n            .addGrid(gbt.maxDepth, [2, 5])\\\n            .addGrid(gbt.maxIter, [5, 10])\\\n            .build())\ncv_gbt = CrossValidator(estimator=gbt, estimatorParamMaps=paramGrid, evaluator=evaluator_gbt, numFolds=5)\ncvModel_gbt = cv_gbt.fit(trainingData)\n\nprint type(cvModel_gbt)\nprint type(cvModel_gbt.bestModel)\n\n\n# Hacemos predicciones\npredictions_test_GBT = cvModel_gbt.transform(testData)\n\n# Mostramos algunas predicciones\npredictions_test_GBT.select(\"prediction\", \"Diabetes\", \"features\").show(5)\n"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":["### 4.3 ÁRBOLES DE DECISIÓN CON VALIDACIÓN CRUZADA  \nLos árboles de decisión asignan cada observación a la clase que ocurre más frecuentemente en la región del árbol (nodo) a la que pertenece dicha observación, teniendo en cuenta la proporción de observaciones del conjunto de entrenamiento que caen en esa misma región del nodo."],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.classification import DecisionTreeClassifier\n\n# Creamos modelo Decision Tree ajustado con k-fold y grid de parametros\ndt = DecisionTreeClassifier(labelCol=\"Diabetes\", featuresCol=\"features\")\nevaluator_dt = MulticlassClassificationEvaluator(labelCol=\"Diabetes\")\nparamGrid  = ParamGridBuilder().addGrid(dt.maxDepth, [1,5,7,9,10,12,14,16,18]).build()\n\ncv_dt = CrossValidator(estimator=dt, estimatorParamMaps=paramGrid, evaluator=evaluator_dt, numFolds=5)\ncvModel_dt = cv_dt.fit(trainingData)\n\nprint type(cvModel_dt)\nprint type(cvModel_dt.bestModel)\n\n\n# Predecimos sobre conjunto test\npredictions_test_dt = cvModel_dt.transform(testData)\npredictions_test_dt.select(\"prediction\", \"Diabetes\", \"features\").show(5)"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":["### 4.4 LINEAR SUPPORT VECTOR MACHINE (SVM) CON VALIDACIÓN CRUZADA  \nSe trata de un clasificador lineal cuyo concepto se basa en la minimización del denominado riesgo estructural, donde una buena separación entre las clases permitirá una clasificación correcta."],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.classification import LinearSVC\n\n# Creamos modelo LSVM ajustado con k-fold y grid de parametros\nlsvc = LinearSVC(labelCol=\"Diabetes\", featuresCol=\"features\", maxIter=10)               \nevaluator_lsvc = MulticlassClassificationEvaluator(labelCol=\"Diabetes\")\nparamGrid = (ParamGridBuilder()\n             .addGrid(lsvc.regParam, [0.05, 0.5, 1.0, 2.0])\n             .addGrid(lsvc.maxIter, [10, 30, 50])\n             .build())\ncv_lsvc = CrossValidator(estimator=lsvc, estimatorParamMaps=paramGrid, evaluator=evaluator_lsvc, numFolds=5)\ncvModel_lsvc = cv_lsvc.fit(trainingData)\n\nprint type(cvModel_lsvc)\nprint type(cvModel_lsvc.bestModel)\n\n# Mostramos los coeficientes y el intercept del lsvm\nprint \"Model Intercept: {0}\".format(cvModel_lsvc.bestModel.intercept) \nprint \"Model Coefficients: {0}\".format(cvModel_lsvc.bestModel.coefficients) \n\n# Predecimos sobre conjunto test\npredictions_test_lsvm = cvModel_lsvc.transform(testData)\npredictions_test_lsvm.select(\"prediction\", \"Diabetes\", \"features\").show(5)                  \n"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"markdown","source":["## 5. EVALUACIÓN Y COMPARACIÓN DE MODELOS"],"metadata":{}},{"cell_type":"code","source":["# Revisamos errores en test y entrenamiento mediante el evaluador de cada modelo.\n# Comparamos los resultados de los modelos con una visualizacion en el siguiente comando.  \n\n# REGRESION LOGISTICA\nprint \"Reg. Logística: Area bajo la curva ROC con test: {0}\".format(lrevaluator.evaluate(predictions_test_lr), {lrevaluator.metricName: \"areaUnderROC\"})\nprint \"Reg. Logística: Area bajo la curva ROC con training: {0}\".format(lrevaluator.evaluate(cvModel_lr.transform(trainingData)), {lrevaluator.metricName: \"areaUnderROC\"})\n\n\n# GBT\nprint \"GBT: Area bajo la curva ROC con test: {0}\".format(evaluator_gbt.evaluate(predictions_test_GBT), {evaluator_gbt.metricName: \"areaUnderROC\"})\nprint \"GBT: Area bajo la curva ROC con training: {0}\".format(evaluator_gbt.evaluate(cvModel_gbt.transform(trainingData)), {evaluator_gbt.metricName: \"areaUnderROC\"})\n\n\n# ARBOLES DE DECISION\nprint \"DT: Area bajo la curva ROC con test: {0}\".format(evaluator_dt.evaluate(predictions_test_dt), {evaluator_dt.metricName: \"areaUnderROC\"})\nprint \"DT: Area bajo la curva ROC con training: {0}\".format(evaluator_dt.evaluate(cvModel_dt.transform(trainingData)), {evaluator_dt.metricName: \"areaUnderROC\"})\n\n\n# LINEAR SUPPORT VECTOR MACHINE (SVM)\nprint \"LSVM: Area bajo la curva ROC con test: {0}\".format(evaluator_lsvc.evaluate(predictions_test_lsvm), {evaluator_lsvc.metricName: \"areaUnderROC\"})\nprint \"LSVM: Area bajo la curva ROC con training: {0}\".format(evaluator_lsvc.evaluate(cvModel_lsvc.transform(trainingData)), {evaluator_lsvc.metricName: \"areaUnderROC\"})\n"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"code","source":["# VISUALIZAMOS COMPARACION MODELOS\n\ny0 = [lrevaluator.evaluate(predictions_test_lr)]\ny1 = [evaluator_gbt.evaluate(predictions_test_GBT)]\ny2 = [evaluator_dt.evaluate(predictions_test_dt)]\ny3 = [evaluator_lsvc.evaluate(predictions_test_lsvm)]\n\nnames=[\"LR\", \"GBT\", \"DT\", \"LSVM\"]\n\nmodelos, compare=plt.subplots()\ncompare=plt.boxplot([y0,y1,y2,y3], labels=names, patch_artist=True, boxprops=dict(facecolor=\"red\"))\nplt.plot(1, y0,'o', markersize=10)\nplt.plot(2, y1,'o', markersize=10)\nplt.plot(3, y2,'o', markersize=10)\nplt.plot(4, y2,'o', markersize=10)\nplt.axis([0,5,0.5,0.9])\n\ndisplay(modelos)\n\n# Vemos que el modelo optimo es la Regresion Logistica, con un area bajo la curva roc de 0.84. Esta tasa es muy alta, con lo que podemos decir que es un modelo fiable y eficiente.\n"],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"markdown","source":["#### REPRESENTACIÓN CURVA ROC PARA EL MODELO ÓPTIMO"],"metadata":{}},{"cell_type":"code","source":["from sklearn.metrics import roc_curve, auc\n\n# Preparamos el set de fpr y tpr\nresults=predictions_test_lr.select(['probability', 'Diabetes'])\nresults_collect = results.collect()\nresults_list = [(float(i[0][0]), 1.0-float(i[1])) for i in results_collect]\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\n \ny_test = [i[1] for i in results_list]\ny_score = [i[0] for i in results_list]\n \nfpr, tpr, _ = roc_curve(y_test, y_score)\nroc_auc = auc(fpr, tpr)\n\nplt.figure()\ncurva_roc=plt.plot(fpr, tpr, label='Curva ROC (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('Tasa Falsos Positivos')\nplt.ylabel('Tasa Verdaderos Positivos')\nplt.title('CURVA ROC MODELO REGRESION LOGISTICA')\nplt.legend(loc=\"lower right\")\nROC=plt.show(curva_roc)\n\ndisplay(ROC)"],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"markdown","source":["#### DISTRIBUCIÓN DE LAS PREDICCIONES"],"metadata":{}},{"cell_type":"code","source":["# Separamos las probabilidades\nall_probs = predictions_test_lr.select(\"probability\").collect()\nnodiab_probs = [i[0][0] for i in all_probs]\ndiab_probs = [i[0][1] for i in all_probs]\n\n# Vemos la distribucion de predicciones para casos con diabetes\ndiabeticas, result_diab = plt.subplots()\nresult_diab=plt.hist(diab_probs, 50, normed=1, facecolor='red', alpha=0.75)\nplt.xlabel('Valores predecidos')\nplt.ylabel('Counts')\nplt.title('Probabilades casos con diabetes')\nplt.grid(True)\n\ndisplay(diabeticas)"],"metadata":{},"outputs":[],"execution_count":40},{"cell_type":"code","source":["# Representamos ahora la distribucion de predicciones para casos sin diabetes\nno_diabeticas, result_nodiab = plt.subplots()\nresult_nodiab=plt.hist(nodiab_probs, 50, normed=1, facecolor='green', alpha=0.75)\nplt.xlabel('Valores predecidos')\nplt.ylabel('Counts')\nplt.title('Probabilades casos sin diabetes')\nplt.grid(True)\n\ndisplay(no_diabeticas)"],"metadata":{},"outputs":[],"execution_count":41},{"cell_type":"markdown","source":["## 6. CONCLUSIONES\n\nEn este estudio proporcionamos nuevas perspectivas al dataset _Pima Indian Diabetes_ mediante un análisis de datos en entorno PySpark.\n\nDurante este análisis hemos identificado la existencia de una correlación positiva entre diabetes y las distintas variables predictoras que se incluyen en el dataset. Además, no se aprecian síntomas de colinealidad entre ellas.\n\nA la hora de realizar el aprendizaje automático supervisado y no supervisado, nos hemos decantado por la librería pyspark.ml ya que proporciona APIs de más alto nivel construidas sobre DataFrames para crear flujos completos (pipelines) de machine learning.  \n\nLa distribución de la clasificación en cada variable sugería que los modelos tipo árbol no iban a resultar del todo eficientes, aún así hemos incluido alguno para comprobarlo. En concreto, hemos estudiado 4 modelos machine learning supervisados de clasificación con validación cruzada: Regresión Logística, Gradient-Boosted Tree, Árboles de decisión y Linear Support Vector Machine. \n\nDe todos estos, la Regresión Logística ha resultado ser el óptimo. Su área bajo la curva ROC (Receiver Operating Characteristic), que  puede interpretarse como la probabilidad de que ante un par de pacientes, una con diabetes y la otra sana, la prueba las clasifique correctamente, es de 0.84. Esto significa que el modelo cuenta con una alta precision y fiabilidad. En futuras investigaciones, sería interesante aplicar algún tipo de normalización o crear variables sintéticas.  \n\nDadas las últimas gráficas que representan la distribución de las predicciones para este modelo óptimo, vemos que las probabilidades son más sesgadas hacia casos sin diabetes. Esto no es muy sorprendente ya que como hemos comentado al principio, el dataset no está equilibrado (presenta más casos sin diabetes que con).   Esta desigualdad influye en los resultados, pero en un futuro se podría eliminar utilizando técnicas de class weight, que actualmente sólo están disponibles en pyspark.mllib. Otra manera sería haciendo down o up-sampling, pero no se han implementado en este proyecto debido a sus desventajas: incrementan el sesgo estadístico y el sobreajuste."],"metadata":{}},{"cell_type":"markdown","source":["## 7. REFERENCIAS  \n  \n  \n- Baier.L y Hansen.R, 2004. Genetic Studies of the Etiology of Type 2 Diabetes in Pima Indians. _Diabetes Journals_; 53(5): 1181-1186.    \n- Booth et al., 2017. Policy and Social Factors Influencing Diabetes among Pima Indians in Arizona, USA. _IISTE_. Vol.7, No.3.    \n- Schulz et al., 2006. Effects of Traditional and Western Environments on Prevalence of Type 2 Diabetes in Pima Indians in Mexico and the U.S. _Diabetes Journals_; 29(8): 1866-1871    \n- World Health Organization (WHO), 2017. Diabetes, datos y cifras.  http://www.who.int/es/news-room/fact-sheets/detail/diabetes \n- World Health Organization (WHO), 2016. Global Report on Diabetes. http://apps.who.int/iris/bitstream/handle/10665/204871/9789241565257_eng.pdf;jsessionid=A6F8442DD9924FD15DF258533FCFF198?sequence=1    \n- Toche, N., 2017. La diabetes, con cifras excesivas y en crecimiento. _El Economista_. https://www.eleconomista.com.mx/arteseideas/La-diabetes-con-cifras-excesivas-y-en-crecimiento-20171113-0097.html\n- Contenido del Máster Telefónica en Big Data & Business Analytics 2017-2018"],"metadata":{}}],"metadata":{"name":"TFM","notebookId":3164243914005431},"nbformat":4,"nbformat_minor":0}
